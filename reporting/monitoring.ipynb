{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, recall_score, precision_score\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import ClassificationPreset\n",
    "from evidently.ui.workspace import Workspace\n",
    "\n",
    "# Define paths\n",
    "WORKSPACE_PATH = \"./reporting/evidently_ui_workspace\"\n",
    "REF_DATA_PATH = \"../data/ref_data.csv\"\n",
    "PROD_DATA_PATH = \"../data/prod_data.csv\"\n",
    "MODEL_PATH = \"../artifacts/model_xgb.pkl\"\n",
    "\n",
    "# Load Evidently workspace\n",
    "workspace = Workspace.create(WORKSPACE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate prod_data with all classes (0 to 27)\n",
    "def generate_prod_data():\n",
    "    # Define the number of samples per class (one per class)\n",
    "    num_samples = 1  # One sample per class\n",
    "\n",
    "    # Sample PCA columns (same as in your provided dataset)\n",
    "    pca_columns = [f\"PCA_{i}\" for i in range(1, 101)]  # PCA_1 to PCA_100\n",
    "    columns = pca_columns + ['target', 'prediction']\n",
    "\n",
    "    # Create the synthetic prod_data dataframe with one sample per class\n",
    "    prod_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Classes 0 to 27\n",
    "    target_classes = list(range(28))  # Classes 0 to 27\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "\n",
    "    # Generate one row per class with random values for PCA columns and corresponding target\n",
    "    for target_class in target_classes:\n",
    "        pca_values = np.random.uniform(low=-10, high=10, size=(1, 100))  # Random PCA values between -10 and 10\n",
    "        prediction = np.random.choice([0, 1])  # Example prediction, adjust if needed\n",
    "        \n",
    "        # Add row for each target class\n",
    "        new_row = np.concatenate([pca_values, np.array([[target_class, prediction]])], axis=1)\n",
    "        prod_data = pd.concat([prod_data, pd.DataFrame(new_row, columns=columns)], ignore_index=True)\n",
    "\n",
    "    # Convert data types for 'target' and 'prediction' columns to match original data types\n",
    "    prod_data['target'] = prod_data['target'].astype(int)\n",
    "    prod_data['prediction'] = prod_data['prediction'].astype(int)\n",
    "\n",
    "    return prod_data\n",
    "\n",
    "def preprocess_data():\n",
    "    \"\"\"Load and preprocess reference and production datasets.\"\"\"\n",
    "    ref_data = pd.read_csv(REF_DATA_PATH)\n",
    "    prod_data = pd.read_csv(PROD_DATA_PATH)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    ref_data = ref_data.loc[:, ~ref_data.columns.str.contains(\"^Unnamed\")]\n",
    "    prod_data = prod_data.loc[:, ~prod_data.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "    # Rename columns\n",
    "    ref_columns = [f\"PCA_{i+1}\" for i in range(100)] + [\"target\"]\n",
    "    ref_data.columns = ref_columns\n",
    "\n",
    "    # Convert PCA columns to numeric\n",
    "    pca_cols = [f\"PCA_{i+1}\" for i in range(100)]\n",
    "    for col in pca_cols:\n",
    "        ref_data[col] = pd.to_numeric(ref_data[col], errors=\"coerce\")\n",
    "        prod_data[col] = pd.to_numeric(prod_data[col], errors=\"coerce\")\n",
    "\n",
    "    ref_data.dropna(subset=pca_cols, inplace=True)\n",
    "    prod_data.dropna(subset=pca_cols, inplace=True)\n",
    "\n",
    "    # Convert target and prediction columns to integers for both datasets\n",
    "    ref_data[\"target\"] = ref_data[\"target\"].astype(int)\n",
    "    ref_data[\"prediction\"] = ref_data[\"prediction\"].astype(int) if \"prediction\" in ref_data else 0  # If there's no prediction column, set it to zero\n",
    "\n",
    "    # Map the float class labels in prod_data to integer class labels\n",
    "    prod_data[\"target\"] = prod_data[\"target\"].astype(int)\n",
    "    \n",
    "    # Ensure prediction is also an integer class for prod_data\n",
    "    prod_data[\"prediction\"] = prod_data[\"prediction\"].astype(int)\n",
    "\n",
    "    return ref_data, prod_data, pca_cols\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the trained model from the specified path.\"\"\"\n",
    "    with open(MODEL_PATH, \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(ref_data, prod_data, pca_cols, model):\n",
    "    \"\"\"Generate predictions and evaluate model performance.\"\"\"\n",
    "    ref_data[\"prediction\"] = model.predict(ref_data[pca_cols])\n",
    "    prod_data[\"prediction\"] = model.predict(prod_data[pca_cols])\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    metrics = {\n",
    "        \"F1 Score\": f1_score(ref_data[\"target\"], ref_data[\"prediction\"], average=\"weighted\"),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(ref_data[\"target\"], ref_data[\"prediction\"]),\n",
    "        \"Recall (Rappel)\": recall_score(ref_data[\"target\"], ref_data[\"prediction\"], average=\"weighted\", zero_division=0),\n",
    "        \"Precision\": precision_score(ref_data[\"target\"], ref_data[\"prediction\"], average=\"weighted\", zero_division=0),\n",
    "    }\n",
    "\n",
    "    print(\"\\n[INFO] Model Performance on Reference Data:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return ref_data, prod_data\n",
    "\n",
    "def build_custom_dashboard(ref_data, prod_data, pca_cols):\n",
    "    \"\"\"Create and display a custom Evidently performance dashboard using classification performance preset.\"\"\"\n",
    "    if prod_data is None:\n",
    "        print(\"[INFO] Production data is None. Using only reference data for the dashboard.\")\n",
    "        prod_data = ref_data.copy()\n",
    "\n",
    "    # Get common labels between target and prediction across both datasets\n",
    "    ref_labels = set(ref_data[\"target\"].unique()) | set(ref_data[\"prediction\"].unique())\n",
    "    prod_labels = set(prod_data[\"target\"].unique()) | set(prod_data[\"prediction\"].unique())\n",
    "    common_labels = sorted(ref_labels & prod_labels)\n",
    "\n",
    "    # Filter out unused labels\n",
    "    ref_data = ref_data[ref_data[\"target\"].isin(common_labels)]\n",
    "    ref_data = ref_data[ref_data[\"prediction\"].isin(common_labels)]\n",
    "    prod_data = prod_data[prod_data[\"target\"].isin(common_labels)]\n",
    "    prod_data = prod_data[prod_data[\"prediction\"].isin(common_labels)]\n",
    "\n",
    "    # Convert to categorical with common categories\n",
    "    ref_data[\"target\"] = pd.Categorical(ref_data[\"target\"], categories=common_labels)\n",
    "    ref_data[\"prediction\"] = pd.Categorical(ref_data[\"prediction\"], categories=common_labels)\n",
    "    prod_data[\"target\"] = pd.Categorical(prod_data[\"target\"], categories=common_labels)\n",
    "    prod_data[\"prediction\"] = pd.Categorical(prod_data[\"prediction\"], categories=common_labels)\n",
    "\n",
    "    # Define column mapping for Evidently\n",
    "    column_mapping = ColumnMapping(\n",
    "        target=\"target\",\n",
    "        prediction=\"prediction\",\n",
    "        numerical_features=pca_cols,\n",
    "    )\n",
    "\n",
    "    # Use preset for classification performance metrics\n",
    "    report = Report(metrics=[ClassificationPreset()])\n",
    "\n",
    "    # Run the report\n",
    "    report.run(reference_data=ref_data, current_data=prod_data, column_mapping=column_mapping)\n",
    "    \n",
    "    # Alternatively, save the report to an HTML file and open it in a browser\n",
    "    report.save(\"evidently_classification_report.html\")\n",
    "\n",
    "    # Check if any issues with the report\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdennour\\AppData\\Local\\Temp\\ipykernel_15484\\3769551257.py:24: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning:\n",
      "\n",
      "[20:15:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model Performance on Reference Data:\n",
      "F1 Score: 0.9885\n",
      "Balanced Accuracy: 0.9885\n",
      "Recall (Rappel): 0.9885\n",
      "Precision: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\abdennour\\.conda\\envs\\sign-language-mlops\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<evidently.report.report.Report object at 0x000001E8E7BF8FE0>\n"
     ]
    }
   ],
   "source": [
    "# Your existing functions (assuming they're defined elsewhere)\n",
    "ref_data, prod_data, pca_cols = preprocess_data()\n",
    "\n",
    "# Generate the synthetic prod_data with all classes\n",
    "prod_data = generate_prod_data()\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Evaluate model performance\n",
    "ref_data, prod_data = evaluate_model(ref_data, prod_data, pca_cols, model)\n",
    "\n",
    "# Create performance dashboard\n",
    "build_custom_dashboard(ref_data, prod_data, pca_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign-language-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
